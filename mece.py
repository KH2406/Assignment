# -*- coding: utf-8 -*-
"""MECE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZyBGDZ6FP-0MsFSoORnwQ7DGI025H2Br
"""

# !pip install -q langchain langchain-community openai ipywidgets pandas numpy requests

import os, json, traceback
from getpass import getpass
from datetime import datetime, timedelta
import numpy as np, pandas as pd
import ipywidgets as widgets
from IPython.display import display, clear_output


# OpenRouter and Mistral for the LLM
# =====================
print("Paste your OpenRouter API key when prompted (press Enter to skip).")
openrouter_key = getpass("OpenRouter API key: ").strip()
if openrouter_key:
    os.environ["OPENAI_API_KEY"] = openrouter_key
    os.environ["OPENAI_API_BASE"] = "https://openrouter.ai/api/v1"
    import openai
    openai.api_key = openrouter_key
    openai.api_base = "https://openrouter.ai/api/v1"


# Backend functions - Dataset creation and Scoring logic
# =====================
TODAY = pd.to_datetime("2025-09-20")
MIN_SEG, MAX_SEG = 100, 20000

def simulate_dataset(n_users=5000, today=TODAY):
    np.random.seed(42)
    user_id = np.arange(1, n_users+1)
    last_order_date = [today - timedelta(days=int(x)) for x in np.random.randint(1, 365, size=n_users)]
    cart_abandoned_date = []
    for _ in range(n_users):
        if np.random.rand() < 0.2:
            days_ago = np.random.randint(0, 14)
            cart_abandoned_date.append(today - timedelta(days=days_ago))
        else:
            cart_abandoned_date.append(pd.NaT)
    avg_order_value = np.round(np.random.exponential(scale=800, size=n_users) + 50)
    avg_order_value = np.minimum(avg_order_value, 15000)
    sessions_last_30d = np.random.poisson(4, size=n_users)
    num_cart_items = np.random.randint(1, 10, size=n_users)
    engagement_score = np.clip(np.random.beta(2, 3, size=n_users), 0, 1)
    profitability_score = np.clip(np.random.beta(2, 2, size=n_users), 0, 1)
    df = pd.DataFrame({
        "user_id": user_id,
        "last_order_date": last_order_date,
        "cart_abandoned_date": cart_abandoned_date,
        "avg_order_value": avg_order_value,
        "sessions_last_30d": sessions_last_30d,
        "num_cart_items": num_cart_items,
        "engagement_score": engagement_score,
        "profitability_score": profitability_score
    })
    df['days_since_abandon'] = (today - pd.to_datetime(df['cart_abandoned_date'])).dt.days
    return df

def build_mece_segments(df, aov_thresholds=(1000,3000), eng_thresholds=(0.4,0.7), prof_threshold=0.6, min_seg=MIN_SEG, max_seg=MAX_SEG):
    df = df.copy()
    lo, hi = aov_thresholds
    df['aov_bucket'] = df['avg_order_value'].apply(
        lambda a: "AOV Other" if pd.isna(a) else ("High AOV" if a > hi else "Mid AOV" if a > lo else "Low AOV"))
    e_lo, e_hi = eng_thresholds
    df['eng_bucket'] = df['engagement_score'].apply(
        lambda e: "Eng Other" if pd.isna(e) else ("High Eng" if e > e_hi else "Med Eng" if e > e_lo else "Low Eng"))
    df['prof_bucket'] = df['profitability_score'].apply(
        lambda p: "Prof Other" if pd.isna(p) else ("High Prof" if p > prof_threshold else "Low Prof"))
    df['segment_raw'] = df['aov_bucket'] + " | " + df['eng_bucket'] + " | " + df['prof_bucket']
    seg_counts = df['segment_raw'].value_counts().to_dict()
    final_map = {seg: seg for seg in seg_counts.keys()}
    def parent_of(seg, levels_up=1):
        parts = seg.split(" | ")
        return "ELSE" if levels_up >= len(parts) else " | ".join(parts[:-levels_up])
    changed, it = True, 0
    while changed and it < 10:
        it += 1
        changed = False
        mapped_sizes = {}
        for raw, mapped in final_map.items():
            mapped_sizes[mapped] = mapped_sizes.get(mapped, 0) + seg_counts.get(raw, 0)
        for raw, mapped in list(final_map.items()):
            if mapped_sizes.get(mapped, 0) < min_seg:
                parent = parent_of(mapped, 1)
                if parent != mapped:
                    final_map[raw] = parent
                    changed = True
    df['final_segment'] = df['segment_raw'].map(final_map)
    return df

def score_segments(df):
    df = df.copy()
    df['recency_factor'] = (7 - df['days_since_abandon'] + 1) / 8.0
    df['conversion_potential_ind'] = df['engagement_score'] * df['recency_factor']
    rng = np.random.default_rng(0)
    df['lift_ind'] = df.apply(lambda row: float(np.clip(
        rng.normal(loc=1.0 + 0.5*(row['engagement_score']-0.5) + 0.4*(row['profitability_score']-0.5), scale=0.12),
        0.5, 2.0)), axis=1)
    df['aov_pct'] = df['avg_order_value'].rank(pct=True)
    df['strategic_fit_ind'] = 0.6*df['aov_pct'] + 0.4*df['profitability_score']
    agg = df.groupby('final_segment').agg(
        size=('user_id','count'),
        conv_pot_mean=('conversion_potential_ind','mean'),
        lift_mean=('lift_ind','mean'),
        profit_mean=('profitability_score','mean'),
        strategic_mean=('strategic_fit_ind','mean'),
        avg_aov=('avg_order_value','mean')
    ).reset_index()
    agg['size_norm'] = (agg['size']-agg['size'].min())/(agg['size'].max()-agg['size'].min()) if agg['size'].max()!=agg['size'].min() else 0
    weights = {'conv_pot':0.32, 'lift':0.22, 'profitability':0.20, 'strategic':0.16, 'size_norm':0.10}
    agg['overall'] = (weights['conv_pot']*agg['conv_pot_mean'] +
                      weights['lift']*(agg['lift_mean']/2.0) +
                      weights['profitability']*agg['profit_mean'] +
                      weights['strategic']*agg['strategic_mean'] +
                      weights['size_norm']*agg['size_norm'])
    agg['valid'] = agg['size'].between(MIN_SEG, MAX_SEG)
    return agg

def tool_build_segments(args_json: str) -> str:
    args = json.loads(args_json)
    df_all = simulate_dataset(5000, TODAY)
    universe = df_all[df_all['cart_abandoned_date'].notna() & (df_all['days_since_abandon'] <= 7)].copy()
    segged = build_mece_segments(universe,
                                aov_thresholds=tuple(args.get('aov_thresholds',(1000,3000))),
                                eng_thresholds=tuple(args.get('eng_thresholds',(0.4,0.7))),
                                prof_threshold=args.get('prof_threshold',0.6),
                                min_seg=args.get('min_seg',MIN_SEG),
                                max_seg=args.get('max_seg',MAX_SEG))
    agg = score_segments(segged)
    agg.to_csv("agent_summary.csv", index=False)
    segged.to_csv("agent_segmented.csv", index=False)
    agg.to_json("agent_segments.json", orient='records')
    return json.dumps({"status":"ok","summary_csv":"agent_summary.csv","segmented_csv":"agent_segmented.csv","segments_count":len(agg)})


# Simple GUI (prompt to qury our agent)
# =====================
input_box = widgets.Textarea(
    placeholder='Type what you want the agent to do (e.g., "Segment users with AOV [1000,3000] and engagement [0.4,0.7]").',
    layout=widgets.Layout(width='100%', height='100px'),
    description='Prompt:'
)
output_box = widgets.Textarea(
    placeholder='Agent output here',
    layout=widgets.Layout(width='100%', height='200px'),
    description='Output:',
    disabled=True
)
button = widgets.Button(description='Run Agent', button_style='success', icon='play')

def on_click(b):
    clear_output(wait=True)
    display(input_box, button, output_box)
    # Fixed thresholds for demo
    args = {
        "aov_thresholds":[1000,3000],
        "eng_thresholds":[0.4,0.7],
        "prof_threshold":0.6,
        "min_seg":100,
        "max_seg":20000
    }
    #files that have the outputs from the agents query.
    result = tool_build_segments(json.dumps(args))
    output_box.value = f"Ran segmentation.\nFiles written:\n- agent_summary.csv\n- agent_segmented.csv\n- agent_segments.json\n\nResult JSON:\n{result}"

button.on_click(on_click)
display(input_box, button, output_box)
`